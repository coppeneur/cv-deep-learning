{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# install libraries if not already installed, uncomment the following lines\n",
    "\n",
    "import sys\n",
    "# !{sys.executable} -m pip install opencv-python opencv-contrib-python matplotlib numpy torch torchvision pandas tqdm scikit-learn seaborn transformers datasets accelerate torchsummary"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "import torchvision.transforms as transforms\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torchsummary import summary"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ddf3b31583221b10",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "from src import dataloader as ds\n",
    "from src import models as m\n",
    "from src import training as t\n",
    "from src import evaluation as eval\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "14ac6bea32393724",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "file_path = 'fer2013.tar.gz'\n",
    "data_path = ds.unpack_tar_gz(file_path)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b3b3315d6da05829",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# dataset is available at https://www.kaggle.com/datasets/ashishpatel26/facial-expression-recognitionferchallenge\n",
    "df = pd.read_csv(data_path)\n",
    "print(df.shape)\n",
    "df.head()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "882103baf9427c6",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "emotion_label = {0: 'anger', 1: 'disgust', 2: 'fear', 3: 'happiness', 4: 'sadness', 5: 'surprise', 6: 'neutral'}"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d2cbd46249659e39",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "df_mapped = df.copy()\n",
    "\n",
    "# Map the emotion labels to their names\n",
    "df_mapped['emotion'] = df_mapped['emotion'].map(emotion_label)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "aa530d3b05c2e874",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "df_mapped.head()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "649ff5e8e9c53e2e",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "df_mapped['Usage'].value_counts()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "be8e65045a15799f",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "df_mapped['emotion'].value_counts()\n",
    "# get class weights of the training set"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a69b58b7c73cc32d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "train_class_weights = df_mapped[df_mapped['Usage'] == 'Training']['emotion'].value_counts(normalize=True)\n",
    "train_class_weights"
   ],
   "id": "e96e410f880e98a1",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# plot the distribution of the emotions\n",
    "df_mapped['emotion'].value_counts().plot(kind='bar')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f646379c2f1ebdbf",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "def pixels_to_image(pixels_str):\n",
    "    pixels = np.fromstring(pixels_str, dtype=int, sep=' ')\n",
    "    image = pixels.reshape(48, 48)\n",
    "    return image\n",
    "\n",
    "\n",
    "# plot each emotion\n",
    "fig, axes = plt.subplots(1, 7, figsize=(14, 2))\n",
    "for i in range(7):\n",
    "    image = pixels_to_image(df[df['emotion'] == i].iloc[0]['pixels'])\n",
    "    axes[i].imshow(image, cmap='gray')\n",
    "    axes[i].set_title(emotion_label[i])\n",
    "    axes[i].axis('off')\n",
    "\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7e895f09387306c9",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "train_transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),  # Randomly flip the image horizontally\n",
    "    transforms.RandomRotation(degrees=10),  # Randomly rotate the image by up to 10 degrees\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
    "    # Randomly change brightness, contrast, and saturation\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5], std=[0.5])\n",
    "])\n",
    "\n",
    "batch_size = 32\n",
    "train_loader, valid_loader, test_loader = ds.get_data_loaders(data_path, batch_size, train_transform)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e3935c07b306be90",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "class_counts = df[df['Usage'] == 'Training']['emotion'].value_counts()\n",
    "class_counts=class_counts.sort_index()\n",
    "train_class_weights = 1.0 / class_counts.values\n",
    "train_class_weights = train_class_weights / np.sum(train_class_weights)\n",
    "print(train_class_weights)\n",
    "train_class_weights = torch.from_numpy(train_class_weights).float()"
   ],
   "id": "f40ab6210226497c",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "model = m.Final_SimpleCNN()\n",
    "summary(model, (1, 48, 48))\n",
    "criteria = torch.nn.CrossEntropyLoss(weight=train_class_weights)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "t.train(model, train_loader, valid_loader, criteria, optimizer, num_epochs=20)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cd732851d3935287",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# Evaluate the model\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "eval.evaluate_model(model, test_loader, criterion)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "373276f62168d82d",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "model = m.Final_IntermediateCNN()\n",
    "summary(model, (1, 48, 48))\n",
    "criteria = torch.nn.CrossEntropyLoss(weight=train_class_weights)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "t.train(model, train_loader, valid_loader, criteria, optimizer, num_epochs=20)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "64ca9e0039aaf731",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "eval.evaluate_model(model, test_loader, criterion)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6a2a6f90c638c752",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "model = m.Final_ComplexCNN()\n",
    "summary(model, (1, 48, 48))\n",
    "criteria = torch.nn.CrossEntropyLoss(weight=train_class_weights)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "t.train(model, train_loader, valid_loader, criteria, optimizer, num_epochs=20)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b9337382c0c95b93",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "eval.evaluate_model(model, test_loader, criterion)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9f7f5bf10388dd58",
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# use saved model\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "model = m.load_model(m.SimpleCNN(), 'bestmodels/SimpleCNN_CrossEntropyLoss_Adam_best_model.pth')\n",
    "eval.evaluate_model(model, test_loader, criterion)"
   ],
   "id": "256de25c9e6694ee",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "for i in range(7):\n",
    "    for image, label in test_loader:\n",
    "        if label[0] == i:\n",
    "            input_image = image[0]\n",
    "            eval.plot_activations(model, input_image, emotion_label[i])\n",
    "            break"
   ],
   "id": "f7967891e5adaf88",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
